<!DOCTYPE html><html><head><title> Decision Tree &middot; wu-kan</title><!-- Begin Jekyll SEO tag v2.7.1 --><meta name="generator" content="Jekyll v3.9.0" /><meta property="og:title" content="Decision Tree" /><meta property="og:locale" content="en_US" /><meta name="description" content="Decision Tree" /><meta property="og:description" content="Decision Tree" /><link rel="canonical" href="http://localhost:4000/2019/11/21/Decision-Tree/" /><meta property="og:url" content="http://localhost:4000/2019/11/21/Decision-Tree/" /><meta property="og:site_name" content="wu-kan" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2019-11-21T00:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Decision Tree" /><meta name="google-site-verification" content="YIKi1rBnyUaS-DMYiluseI5kZzTwjCkTFmKkSkMZDJk" /><meta name="baidu-site-verification" content="szbTSfUGAB" /> <script type="application/ld+json"> {"@type":"BlogPosting","url":"http://localhost:4000/2019/11/21/Decision-Tree/","datePublished":"2019-11-21T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2019/11/21/Decision-Tree/"},"headline":"Decision Tree","description":"Decision Tree","dateModified":"2019-11-21T00:00:00+08:00","@context":"https://schema.org"}</script> <!-- End Jekyll SEO tag --><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1" /><meta http-equiv="content-type" content="text/html; charset=utf-8" /><link rel="alternate" href="/feed.xml" title="RSS" type="application/rss+xml" /><link rel="apple-touch-icon-precomposed" href="https://gravatar.loli.net/avatar/289efba375d63424de3c49569c446744?s=320" /><link rel="shortcut icon" href="https://gravatar.loli.net/avatar/289efba375d63424de3c49569c446744?s=32" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/combine/gh/poole/lanyon@v1.1.0/public/css/poole.min.css,gh/poole/lanyon@v1.1.0/public/css/lanyon.min.css,gh/poole/lanyon@v1.1.0/public/css/syntax.min.css" /> <script async="async" src="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/js/all.min.js" ></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Dreamer-Paul/Pio@2.4/static/pio.min.css" /><style> @media only print { .pio-container { display: none; } }</style><script async="async" src="https://cdn.jsdelivr.net/combine/gh/Dreamer-Paul/Pio@2.4/static/l2d.min.js,gh/Dreamer-Paul/Pio@2.4/static/pio.min.js" onload=' let pio_container = document.createElement("div"); pio_container.classList.add("pio-container"); pio_container.classList.add("right"); pio_container.style.bottom = "-2rem"; pio_container.style.zIndex = "1"; document.body.insertAdjacentElement("beforeend", pio_container); let pio_action = document.createElement("div"); pio_action.classList.add("pio-action"); pio_container.insertAdjacentElement("beforeend", pio_action); let pio_canvas = document.createElement("canvas"); pio_canvas.id = "pio"; pio_canvas.style.width = "14rem"; pio_canvas.width = "600"; pio_canvas.height = "800"; pio_container.insertAdjacentElement("beforeend", pio_canvas); let pio = new Paul_Pio({ "mode": "fixed", "hidden": true, "night": "for(let i=7; i<16; ++i) if(document.body.classList.contains(`theme-base-0`+i.toString(16))) { document.body.classList.remove(`theme-base-0`+i.toString(16)); document.body.classList.add(`theme-base-0`+((i-6)%9+7).toString(16)); break; }", "content": { "link": ["https:\/\/jekyll-theme-WuK.wu-kan.cn"], "skin": ["要换成我的朋友吗？", "让她放个假吧~"], "hidden": true, "custom": [{ "selector": "a", "type": "link", }, { "selector": ".sidebar-toggle", "text": "打开侧边栏叭~" }, { "selector": ".effect-info", "text": "哇，你发现了什么！" }, { "selector": "#sidebar-search-input", "text": "想搜索什么呢？很多干货哦！" }, { "selector": "#toc", "text": "这是目录~" }, { "selector": ".page-title", "text": "这是标题~" }, { "selector": ".v", "text": "评论没有审核，要对自己的发言负责哦~" }] }, "model": [ "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/33/model.2018.bls-winter.json", "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/platelet-2/model.json", "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/xiaomai/xiaomai.model.json", "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/mashiro/seifuku.model.json", "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/Violet/14.json", "https:\/\/cdn.jsdelivr.net/gh/xiaoski/live2d_models_collection/Kobayaxi/Kobayaxi.model.json", "https:\/\/cdn.jsdelivr.net/gh/xiaoski/live2d_models_collection/mikoto/mikoto.model.json", "https:\/\/cdn.jsdelivr.net/gh/xiaoski/live2d_models_collection/uiharu/uiharu.model.json"] });' ></script> <script src='https://zz.bdstatic.com/linksubmit/push.js' async="async" ></script><style> .wrap { transition-property: width,background-size,transform; transition-duration: .3s; transition-timing-function: ease-in-out; min-height: 100%; display: inline-block; background-size: 100% auto; background-position: 0% 0%; background-repeat: no-repeat; background-attachment: fixed; background-image: url(https://Mizuno-Ai.wu-kan.cn/pixiv/74559485_p1.webp); } @media (min-aspect-ratio: 2400/1850) { .wrap { background-image: url(https://Mizuno-Ai.wu-kan.cn/pixiv/71932901_p0.webp); } } .sidebar-overlay #sidebar-checkbox:checked ~ .wrap { width: calc(100% - 14rem); background-size: calc(100% - 14rem) auto; transform: translateX(14rem); } .layout-reverse.sidebar-overlay #sidebar-checkbox:checked ~ .wrap { transform: translateX(0); }</style><style> .sidebar, html, h1, h2, h3, h4, h5, h6 { font-family: "Courier New", "Courier", "Hiragino Sans GB", "WenQuanYi Micro Hei", "Microsoft YaHei Light", "Microsoft JhengHei", monospace; }</style><style> td, th { padding: 0px; border: 0px; } table { border: 0px; } table tbody { display: block; overflow: scroll; } table thead, tbody tr { display: table; table-layout: fixed; width: 100%; }</style><style> img { display: inline-block; margin: 0; }</style><style> ::-webkit-scrollbar { width: 3px; height: 3px; } ::-webkit-scrollbar-thumb { background-image: linear-gradient(45deg, Cyan 0%, Magenta 50%, Yellow 100%); }</style><style> ::selection { color: White; background: Black; }</style><body class="theme-base-0d layout-reverse sidebar-overlay"> <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular styles, `#sidebar-checkbox` for behavior. --> <input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox" /> <!-- Toggleable sidebar --><div class="sidebar" id="sidebar"><div class="sidebar-item"><div class="effect effect-right_to_left"> <img class="effect-img" src="https://gravatar.loli.net/avatar/289efba375d63424de3c49569c446744?s=320" alt="img" /><div class="effect-info"> SYSU超算17级在读<br/> 水野爱<br/> HPC<br/> 田宫例四驱车<br/> <a href="mailto:i@wu-kan.cn"> <i class="fas fa-envelope"></i> </a> <a href="https://github.com/wu-kan"> <i class="fab fa-github"></i> </a> <a href="https://codeforces.com/profile/WuK"> <i class="fas fa-chart-bar"></i> </a> <a href="https://vjudge.net/user/WuK"> <i class="fas fa-smile"></i> </a> <a href="https://www.zhihu.com/people/wu.kan/activities"> <i class="fab fa-zhihu"></i> </a> <iframe src="https://music.163.com/outchain/player?type=0&id=155059595&auto=0&height=32" width=100% height=52 frameborder="no" border="0" marginwidth="0" marginheight="0" ></iframe></div></div></div><nav class="sidebar-nav"> <a class="sidebar-nav-item" href="/"> <i class="fas fa-home fa-fw"></i> 首页 </a> <a class="sidebar-nav-item" href="/comments/"> <i class="fas fa-comments fa-fw"></i> 留言 </a> <a class="sidebar-nav-item" href="/tags/"> <i class="fas fa-tags fa-fw"></i> 标签 </a> <a class="sidebar-nav-item" href="/archive/"> <i class="fas fa-archive fa-fw"></i> 归档 </a> <a class="sidebar-nav-item" href="/merger/"> <i class="fas fa-coffee fa-fw"></i> 打赏 </a></nav><div class="sidebar-item"><style> #sidebar-search-input { background: none; border: none; color: White; width: 100%; } #sidebar-search-results-container { overflow: auto auto; max-height: 66.6vh; }</style><input id="sidebar-search-input" placeholder="搜索博文" /><ol id="sidebar-search-results-container" ></ol><script src='https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.9.1' async='async' onload=' SimpleJekyllSearch({ json: "/assets/simple-jekyll-search/search.json", searchInput: document.getElementById("sidebar-search-input"), resultsContainer: document.getElementById("sidebar-search-results-container"), searchResultTemplate: `<li><a href="{url}">{title}</a>`, limit: 999, fuzzy: true })' ></script><style> #toc { overflow: auto auto; max-height: 66.6vh; }</style><ol id="toc"><li><a href="#decision-tree">Decision Tree</a><ol><li><a href="#id3">ID3</a><ol><li><a href="#algorithm">Algorithm</a><li><a href="#stop-cases">Stop Cases</a><li><a href="#id3-shortcomings">ID3 shortcomings</a><li><a href="#entropy">Entropy</a><li><a href="#information-gain">Information gain</a></ol><li><a href="#c45-and-cart">C4.5 and CART</a><li><a href="#%E4%B8%80%E4%BA%9B%E5%8F%8D%E4%BE%8B">一些反例</a></ol><li><a href="#datasets">Datasets</a><li><a href="#tasks">Tasks</a><li><a href="#codes-and-results">Codes and Results</a><ol><li><a href="#codesid3cpp">CodesID3.cpp</a><li><a href="#codesdtpy">CodesDT.py</a></ol></ol><style> .sidebar-checkbox { display: none; } .sidebar-toggle { position: fixed; }</style><style> .sidebar { overflow: scroll; min-height: 101%; }</style><style> .effect { margin: 1rem; perspective: 900px; } .effect-info { text-align: center; position: absolute; top: 0; transform-style: preserve-3d; } .effect-img { z-index: 11; width: 100%; height: 100%; position: relative; transition: all 0.5s ease-in-out; } .effect-img:before { position: absolute; display: block; } .effect-right_to_left .effect-img { transform-origin: 0% 50%; } .effect-right_to_left:hover .effect-img { transform: rotate3d(0, 1, 0, -180deg); }</style><div> <i class="fas fa-cog fa-spin fa-fw"></i> <span id="run_time_day"> <i class="fas fa-spinner fa-pulse"></i> </span>天 <span id="run_time_hour"> <i class="fas fa-spinner fa-pulse"></i> </span>时 <span id="run_time_minute"> <i class="fas fa-spinner fa-pulse"></i> </span>分 <span id="run_time_second"> <i class="fas fa-spinner fa-pulse"></i> </span>秒 <script> setInterval(function (d,h,m,s,b) { function setzero(i) { return i < 10 ? "0" + i : i; } let BirthDay = new Date(b); let today = new Date(); let timeold = (today.getTime() - BirthDay.getTime()); let sectimeold = timeold / 1000; let secondsold = Math.floor(sectimeold); let msPerDay = 24 * 60 * 60 * 1000; let e_daysold = timeold / msPerDay; let daysold = Math.floor(e_daysold); let e_hrsold = (e_daysold - daysold) * 24; let hrsold = Math.floor(e_hrsold); let e_minsold = (e_hrsold - hrsold) * 60; let minsold = Math.floor((e_hrsold - hrsold) * 60); let seconds = Math.floor((e_minsold - minsold) * 60); d.textContent = daysold; h.textContent = setzero(hrsold); m.textContent = setzero(minsold); s.textContent = setzero(seconds); }, 1000, document.getElementById("run_time_day"), document.getElementById("run_time_hour"), document.getElementById("run_time_minute"), document.getElementById("run_time_second"), "10/04/2017 11:03:56")// 这是我第一篇CSDN博客的时间 </script></div><div><div> <i class="fas fa-eye fa-fw"></i> <span id="busuanzi_value_page_pv"> <i class="fas fa-spinner fa-pulse"></i> </span>次</div><div> <i class="fas fa-paw fa-fw"></i> <span id="busuanzi_value_site_pv"> <i class="fas fa-spinner fa-pulse"></i> </span>枚</div><div> <i class="fas fa-user-friends fa-fw"></i> <span id="busuanzi_value_site_uv"> <i class="fas fa-spinner fa-pulse"></i> </span>人</div><script src='https://cdn.jsdelivr.net/npm/busuanzi@2.3.0' async='async' ></script></div><div> <i class="fas fa-thumbs-up fa-fw"></i> <a href="https://jekyll-theme-WuK.wu-kan.cn"> jekyll-theme-WuK </a></div><div> <i class="fas fa-copyright fa-fw"></i> 2017-2021 WuK</div><div> <i class="fas fa-info-circle fa-fw"></i> <a href="http://beian.miit.gov.cn"> 粤ICP备 20024947号 </a></div><div> <img src="https://i.loli.net/2021/03/17/Y47tDZTrcy2xwRa.png" class="fa-fw"></img> <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=34070202000407"> 皖公网安备 34070202000407号 </a></div></div></div><!-- Wrap is the content to shift when toggling the sidebar. We wrap the content to avoid any CSS collisions with our real content. --><div class="wrap"><style> @media only screen { pre { max-height: 66.6vh; overflow: auto; } }</style><style> .container { min-width: 66.6%; } @media only print { .container { min-width: 100%; } }</style><style> .container.content { padding: 2rem; box-shadow: 0 0 2rem rgba(255,255,255,0.9); background-color: rgba(255,255,255,0.9); animation-duration: 2s; animation-name: fadeIn; } @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }</style><div class="container content"><div class="page"><h1 class="page-title">Decision Tree</h1><div class="post"> <span class="post-date"> <i class="fas fa-calendar-day fa-fw"></i> 21 Nov 2019 <i class="fas fa-file-word fa-fw"></i> 10258字 <i class="fas fa-clock fa-fw"></i> 35分 <br/> <i class="fas fa-coffee fa-fw"></i> <a href="/merger/">如果这篇博客帮助到你，可以请我喝一杯咖啡~</a> <br/> <i class="fab fa-creative-commons-by fa-fw"></i> <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="license"> CC BY 4.0 </a> （除特别声明或转载文章外） </span><h2 id="decision-tree">Decision Tree</h2><h3 id="id3">ID3</h3><p>ID3 (Iterative Dichotomiser 3) was developed in 1986 by Ross Quinlan. The algorithm creates a multiway tree, finding for each node (i.e. in a greedy manner) the categorical feature that will yield the largest information gain for categorical targets. Trees are grown to their maximum size and then a pruning step is usually applied to improve the ability of the tree to generalise to unseen data.</p><h4 id="algorithm">Algorithm</h4><ul><li>Begins with the original set $S$ as the root node.<li>Calculate the entropy of every attribute $a$ of the data set $S$.<li>Partition the set $S$ into subsets using the attribute for which the resulting entropy after splitting is minimized; or, equivalently, information gain is maximum.<li>Make a decision tree node containing that attribute.<li>Recur on subsets using remaining attributes.</ul><h4 id="stop-cases">Stop Cases</h4><ul><li>every element in the subset belongs to the same class; in which case the node is turned into a leaf node and labelled with the class of the examples.<li>there are no more attributes to be selected, but the examples still do not belong to the same class. In this case, the node is made a leaf node and labelled with the most common class of the examples in the subset.<li>there are no examples in the subset, which happens when no example in the parent set was found to match a specific value of the selected attribute.</ul><h4 id="id3-shortcomings">ID3 shortcomings</h4><ul><li>ID3 does not guarantee an optimal solution.<li>ID3 can overfit the training data.<li>ID3 is harder to use on continuous data.</ul><h4 id="entropy">Entropy</h4><p>Entropy $H(S)$ is a measure of the amount of uncertainty in the set $S$.</p><p>$H(S)=\sum_{x\in X}-p(x)\log_2p(x)$</p><p>where</p><ul><li>$S$ is the current dataset for which entropy is being calculated<li>$X$ is the set of classes in $S$<li>$p(x)$ is the proportion of the number of elements in class $x$ to the number of elements in set $S$.</ul><h4 id="information-gain">Information gain</h4><p>Information gain $IG(A)$ is the measure of the difference in entropy from before to after the set $S$ is split on an attribute $A$. In other words, how much uncertainty in $S$ was reduced after splitting set $S$ on attribute $A$.</p><p>$IG(S,A)=H(S)-\sum_{t\in T}p(t)H(t)=H(S)-H(S\vert A)$</p><p>where</p><ul><li>$H(S)$ is the entropy of set $S$<li>$T$ is the subsets created from splitting set $S$ by attribute $A$ such that $S=\cup_{t\in T}t$<li>$p(t)$ is the proportion of the number of elements in $t$ to the number of elements in set $S$<li>$H(t)$ is the entropy of subset $t$.</ul><h3 id="c45-and-cart">C4.5 and CART</h3><p>C4.5 is the successor to ID3 and removed the restriction that features must be categorical by dynamically defining a discrete attribute (based on numerical variables) that partitions the continuous attribute value into a discrete set of intervals. C4.5 converts the trained trees (i.e. the output of the ID3 algorithm) into sets of if-then rules. These accuracy of each rule is then evaluated to determine the order in which they should be applied. Pruning is done by removing a rule’s precondition if the accuracy of the rule improves without it.</p><p>C5.0 is Quinlan’s latest version release under a proprietary license. It uses less memory and builds smaller rulesets than C4.5 while being more accurate.</p><p>CART (Classification and Regression Trees) is very similar to C4.5, but it differs in that it supports numerical target variables (regression) and does not compute rule sets. CART constructs binary trees using the feature and threshold that yield the largest information gain at each node.</p><h3 id="一些反例">一些反例</h3><ol><li><a href="https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md">内容丰富，但有不少错误</a><li><a href="https://en.wikipedia.org/wiki/Decision_tree_learning">维基百科</a><li><a href="https://blog.csdn.net/moxigandashu/article/details/71305273?locationNum=9&amp;fps=1">完全抄袭《机器学习实战》</a><li><a href="https://blog.csdn.net/wzmsltw/article/details/51057311">部分抄袭《机器学习实战》</a></ol><h2 id="datasets">Datasets</h2><p>The <a href="http://archive.ics.uci.edu/ml/index.php">UCI dataset</a> is the most widely used dataset for machine learning. If you are interested in other datasets in other areas, you can refer to <a href="https://www.zhihu.com/question/63383992/answer/222718972">https://www.zhihu.com/question/63383992/answer/222718972</a>.</p><p>Today’s experiment is conducted with the <strong>Adult Data Set</strong> which can be found in <a href="http://archive.ics.uci.edu/ml/datasets/Adult">http://archive.ics.uci.edu/ml/datasets/Adult</a>.</p><table><thead><tr><th>Data Set Characteristics:<th>Multivariate<th>Number of Instances:<th>48842<th>Area:<th>Social<tbody><tr><td>Attribute Characteristics:<td>Categorical, Integer<td>Number of Attributes:<td>14<td>Date Donated:<td>1996-05-01<tr><td>Associated Tasks:<td>Classification<td>Missing Values?<td>Yes<td>Number of Web Hits:<td>1655259</table><p>You can also find 3 related files in the current folder, <a href="http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names">adult.name</a> is the description of <strong>Adult Data Set</strong>, <a href="http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data">adult.data</a> is the training set, and <a href="http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test">adult.test</a> is the testing set. There are 14 attributes in this dataset:</p><pre><code class="language-markdown">income: &gt;50K, &lt;=50K.

1. age: continuous.
2. workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov,
   State-gov, Without-pay, Never-worked.
3. fnlwgt: continuous.
4. education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm,
   Assoc-voc, 9th, 7th-8th, 12th, Masters, 5. 1st-4th, 10th, Doctorate, 5th-6th,
   Preschool.
5. education-num: continuous.
6. marital-status: Married-civ-spouse, Divorced, Never-married, Separated,
   Widowed, Married-spouse-absent, Married-AF-spouse.
7. occupation: Tech-support, Craft-repair, Other-service, Sales,
   Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct,
   Adm-clerical,Farming-fishing,Transport-moving,Priv-house-serv,Protective-serv,
   Armed-Forces.
8. relationship: Wife,Own-child,Husband,Not-in-family,Other-relative,Unmarried.
9. race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.
10. sex: Female, Male.
11. capital-gain: continuous.
12. capital-loss: continuous.
13. hours-per-week: continuous.
14. native-country: United-States, Cambodia,England,Puerto-Rico,Canada,Germany,
    Outlying-US(Guam-USVI-etc),India,Japan,Greece, South,China,Cuba,Iran,Honduras,
    Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France,
    Dominican-Republic,Laos,Ecuador,Taiwan, Haiti, Columbia,Hungary,Guatemala,
    Nicaragua,Scotland,Thailand,Yugoslavia,El-Salvador, Trinadad&amp;Tobago,Peru,Hong,
    Holand-Netherlands.
</code></pre><p>Prediction task is to determine whether a person makes over 50K a year.</p><h2 id="tasks">Tasks</h2><p>Given the training dataset <a href="http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data">adult.data</a> and the testing dataset <a href="http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test">adult.test</a>, please accomplish the prediction task to determine whether a person makes over 50K a year in <a href="http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test">adult.test</a> by using ID3 (or C4.5, CART) algorithm (C++ or Python), and compute the accuracy.</p><ul><li>You can process the continuous data with \textbf{bi-partition} method.<li>You can use prepruning or postpruning to avoid the overfitting problem.<li>You can assign probability weights to solve the missing attributes (data) problem.</ul><h2 id="codes-and-results">Codes and Results</h2><h3 id="codesid3cpp">Codes<code>ID3.cpp</code></h3><p>按照<code>csv</code>格式读入，然后进行数据清洗。我写的 ID3 决策树框架接受一个<code>vector&lt;vector&lt;int&gt;&gt;</code>用于训练，其中每一行是一个训练数据的离散值，第 0 列代表要预测的标签。由于 ID3 算法仅支持离散值的预测，这里我直接将连续的数据清洗掉了，这也许是预测成功率不那么高的原因吧（就是菜，别找借口了）。</p><p>代码总量仅<strong>145</strong>行，而核心的决策树代码仅<strong>55</strong>行！</p><pre><code class="language-cpp">#include &lt;bits/stdc++.h&gt;
using namespace std;
vector&lt;vector&lt;string&gt;&gt; read_csv(string s)
{
	vector&lt;vector&lt;string&gt;&gt; r;
	for (ifstream fin(s); getline(fin, s);)
	{
		r.push_back({});
		for (istringstream sin(s); getline(sin, s, ',');)
			r.back().push_back(s);
	}
	return r;
}
void clean_data_test(
	vector&lt;vector&lt;string&gt;&gt; _data,
	vector&lt;vector&lt;string&gt;&gt; _test,
	vector&lt;vector&lt;int&gt;&gt; &amp;data,
	vector&lt;vector&lt;int&gt;&gt; &amp;test)
{
	int cols = 0;
	for (auto &amp;it : _data)
	{
		cols = max(cols, (int)it.size());
		for (auto &amp;jt : it)
		{
			string s;
			for (auto c : jt)
				if (isgraph(c) &amp;&amp; c != '.')
					s += c;
			jt = s;
		}
	}
	for (auto &amp;it : _test)
	{
		cols = max(cols, (int)it.size());
		for (auto &amp;jt : it)
		{
			string s;
			for (auto c : jt)
				if (isgraph(c) &amp;&amp; c != '.')
					s += c;
			jt = s;
		}
	}
	vector&lt;int&gt; valid_col{14, 1, 3, 5, 6, 7, 8, 9, 13}; //保留离散列
	map&lt;int, map&lt;string, int&gt;&gt; mp;
	for (int i : valid_col)
	{
		for (const auto &amp;it : _data)
			if (it.size() == cols)
				if (!mp[i].count(it[i]))
					mp[i].emplace(it[i], mp[i].size());
		for (const auto &amp;it : _test)
			if (it.size() == cols)
				if (!mp[i].count(it[i]))
					mp[i].emplace(it[i], mp[i].size());
	}
	data.clear();
	for (const auto &amp;it : _data)
		if (it.size() == cols)
		{
			data.push_back({});
			for (auto id : valid_col)
				data.back().push_back(mp[id][it[id]]);
		}
	test.clear();
	for (const auto &amp;it : _test)
		if (it.size() == cols)
		{
			test.push_back({});
			for (auto id : valid_col)
				test.back().push_back(mp[id][it[id]]);
		}
}
struct IterativeDichotomiser3
{
	int val, dim;						 //这个点的值，这个点的特征维度
	map&lt;int, IterativeDichotomiser3&gt; ch; //划分维度对应取值的子节点
	IterativeDichotomiser3(const vector&lt;vector&lt;int&gt;&gt; &amp;data)
	{
		pair&lt;double, int&gt; p{-1e9, -1};
		map&lt;int, int&gt; mp;
		for (const auto &amp;it : data)
			++mp[it[0]]; //用于统计这一维的频数
		double orgin_entropy = 0;
		for (auto it : mp)
		{
			p = max(p, {it.second, it.first});
			double pr = (double)it.second / data.size();
			orgin_entropy -= pr * log2(pr);
		}
		val = p.second;
		if (mp.size() &lt; 2) //剪枝，只有一类
			return;
		p = {-1e9, -1};
		for (int i = 1; i &lt; data[0].size(); ++i) //i==0是类别标签
			if (data[0][i] &gt;= 0)				 //选择未删除的维度
			{
				double gain = orgin_entropy; //要计算第i维的信息增益
				map&lt;int, map&lt;int, int&gt;&gt; mp;
				for (const auto &amp;it : data)
					++mp[it[i]][it[0]];
				for (const auto &amp;it : mp)
				{
					double subset = 0, entropy = 0;
					for (auto jt : it.second) //计算划分出的子集大小
						subset += jt.second;
					for (auto jt : it.second) //计算子集信息熵
						entropy -= (jt.second / subset) * log2(jt.second / subset);
					gain -= entropy * subset / data.size();
				}
				p = max(p, {gain, i}); //选择信息增益最大的特征作为结点的特征
			}
		dim = p.second;
		if (dim &lt; 0) //未找到可用于划分的维度，同样结束
			return;
		map&lt;int, vector&lt;vector&lt;int&gt;&gt;&gt; mmp;
		for (const auto &amp;it : data)
		{
			mmp[it[dim]].push_back(it);
			mmp[it[dim]].back().at(dim) = -1; //删除这一维的信息
		}
		for (const auto &amp;it : mmp)
			ch.emplace(it);
	}
	int ask(const vector&lt;int&gt; &amp;test) const
	{
		return ch.count(test[dim]) ? ch.at(test[dim]).ask(test) : val;
	}
};
int main()
{
	vector&lt;vector&lt;int&gt;&gt; data, test;
	clean_data_test(
		read_csv("adult.data"),
		read_csv("adult.test"),
		data,
		test);
	IterativeDichotomiser3 id3(data);
	double success = 0;
	for (const auto &amp;it : test)
		if (id3.ask(it) == it[0])
			success += 1;
	cout &lt;&lt; success / test.size();
}
</code></pre><p>运行下述指令编译。</p><pre><code class="language-bash">g++ ID3.cpp -o ID3 -O3 -std=c++11
</code></pre><p>计时运行并得到预测准确率。</p><pre><code class="language-bash">$ time ./ID3
0.814385
real    0m0.266s
user    0m0.219s
sys     0m0.000s
</code></pre><h3 id="codesdtpy">Codes<code>DT.py</code></h3><p>自己手动实现完 C++版本的决策树之后，再来和 sklearn 库里面实现的决策树进行一个比较~由于是直接调包实现的数据读入、清洗还有决策树算法，这里代码非常的少了…</p><pre><code class="language-python">from sklearn.tree import DecisionTreeClassifier
import pandas
import numpy


def get_data_set(filename):
    data = pandas.read_csv(filename, names=(
        "age, workclass, fnlwgt, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, income").split(', '))
    target = data['income']
    data = data.drop('income', axis=1)
    numeric_features = [c for c in data if data[c].dtype.kind in (
        'i', 'f')]  # 提取数值类型为整数或浮点数的变量
    numeric_data = data[numeric_features]
    data = data.drop(numeric_features, 1)
    # pandas.factorize即可将分类变量转换为数值表示
    data = data.apply(lambda x: pandas.factorize(x)[0])
    # apply运算将转换函数应用到每一个变量维度
    features = pandas.concat([numeric_data, data], axis=1)
    # 收入水平 "&gt;50K" 记为1，「&lt;=50K」 记为0
    return features.values.astype(numpy.float32), (target.values == ' &gt;50K').astype(numpy.int32)


#X_train, y_train = get_data_set('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data')
#X_test, y_test = get_data_set('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test')
X_train, y_train = get_data_set('adult.data')
X_test, y_test = get_data_set('adult.test')
clf = DecisionTreeClassifier(max_depth=48)
clf.fit(X_train, y_train)
# print(clf.score(X_train, y_train, sample_weight=None))
print(clf.score(X_test, y_test, sample_weight=None))
</code></pre><blockquote><p>运行下述指令得到预测准确率。</p><pre><code class="language-bash">$ python DT.py
0.9999692884125181
</code></pre><p>是我太菜了，告辞…</p></blockquote><p>感谢 @Leo 的指正，看来去年我手敲的决策树不是那么菜嘿嘿。</p><pre><code class="language-bash">$ python DT.py
0.7686874270622198
</code></pre></div><script repo="wu-kan/utterances-storage" src="https://utteranc.es/client.js" issue-term="url" theme="github-light" crossorigin="anonymous" async="async" ></script></div></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" /><style> .katex-display>.katex { white-space: normal; }</style><script src="https://cdn.jsdelivr.net/combine/npm/katex@0.13.11/dist/katex.min.js,npm/katex@0.13.11/dist/contrib/auto-render.min.js" async="async" onload='renderMathInElement(document.body, { delimiters: [{left: "$$", right: "$$", display: true}, { left: "$", right: "$", display: false }, {left: "\\(", right: "\\)", display: false}, {left: "\\[", right: "\\]", display: true}]})' ></script><style> pre.language-mermaid, code.language-mermaid { display: none; } @media only screen { .mermaid { overflow: auto auto; max-width: 100%; max-height: 66.6vh; } }</style><script src="https://cdn.jsdelivr.net/npm/mermaid@8.10.1/dist/mermaid.min.js" async="async" onload=' for(let x of document.getElementsByClassName("language-mermaid")) if(x.nodeName=="CODE") { let m = document.createElement("div"); m.classList.add("mermaid"); m.textContent = x.textContent; x.parentNode.insertAdjacentElement("beforebegin", m); }' ></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/combine/npm/prismjs@1.23.0/plugins/line-numbers/prism-line-numbers.min.css,npm/prismjs@1.23.0/plugins/toolbar/prism-toolbar.min.css,npm/prismjs@1.23.0/plugins/match-braces/prism-match-braces.min.css,npm/prism-themes@1.5.0/themes/prism-nord.min.css" /> <script src="https://cdn.jsdelivr.net/combine/npm/prismjs@1.23.0/components/prism-core.min.js,npm/prismjs@1.23.0/plugins/autoloader/prism-autoloader.min.js,npm/prismjs@1.23.0/plugins/line-numbers/prism-line-numbers.min.js,npm/prismjs@1.23.0/plugins/toolbar/prism-toolbar.min.js,npm/prismjs@1.23.0/plugins/match-braces/prism-match-braces.min.js" async="async" data-autoloader-path="https://cdn.jsdelivr.net/npm/prismjs@1.23.0/components/" onload=' for(let x of document.getElementsByClassName("content")) x.classList.add("line-numbers","match-braces"); Prism.plugins.toolbar.registerButton("select-code", function (env) { let button = document.createElement("button"); button.textContent = "select this " + env.language; button.addEventListener("click", function () { if (document.body.createTextRange) { let range = document.body.createTextRange(); range.moveToElementText(env.element); range.select(); } else if (window.getSelection) { let selection = window.getSelection(); let range = document.createRange(); range.selectNodeContents(env.element); selection.removeAllRanges(); selection.addRange(range); } }); return button; })' ></script></div><label for="sidebar-checkbox" class="sidebar-toggle"></label>
